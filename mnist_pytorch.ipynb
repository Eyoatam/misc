{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar to:  https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.MNIST(\n",
    "    root=\"data\", train=True, download=True, transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\", train=False, download=True, transform=ToTensor()\n",
    ")\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(\n",
    "        f\"\\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model initialization\n",
    "model = NeuralNetwork()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.05 # to make the model converge faster\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "epochs = 35\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.298847  [   64/60000]\n",
      "loss: 1.536941  [ 6464/60000]\n",
      "loss: 0.560022  [12864/60000]\n",
      "loss: 0.409896  [19264/60000]\n",
      "loss: 0.470079  [25664/60000]\n",
      "loss: 0.347766  [32064/60000]\n",
      "loss: 0.424074  [38464/60000]\n",
      "loss: 0.268754  [44864/60000]\n",
      "loss: 0.180883  [51264/60000]\n",
      "loss: 0.159479  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Avg loss: 0.295276 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.264557  [   64/60000]\n",
      "loss: 0.179156  [ 6464/60000]\n",
      "loss: 0.201183  [12864/60000]\n",
      "loss: 0.190053  [19264/60000]\n",
      "loss: 0.230725  [25664/60000]\n",
      "loss: 0.152161  [32064/60000]\n",
      "loss: 0.238925  [38464/60000]\n",
      "loss: 0.170505  [44864/60000]\n",
      "loss: 0.185057  [51264/60000]\n",
      "loss: 0.265849  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.214935 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.348719  [   64/60000]\n",
      "loss: 0.204187  [ 6464/60000]\n",
      "loss: 0.152118  [12864/60000]\n",
      "loss: 0.294435  [19264/60000]\n",
      "loss: 0.242475  [25664/60000]\n",
      "loss: 0.393543  [32064/60000]\n",
      "loss: 0.132958  [38464/60000]\n",
      "loss: 0.177040  [44864/60000]\n",
      "loss: 0.197152  [51264/60000]\n",
      "loss: 0.142607  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 95.4%, Avg loss: 0.155217 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.214693  [   64/60000]\n",
      "loss: 0.212933  [ 6464/60000]\n",
      "loss: 0.120291  [12864/60000]\n",
      "loss: 0.260818  [19264/60000]\n",
      "loss: 0.090698  [25664/60000]\n",
      "loss: 0.086284  [32064/60000]\n",
      "loss: 0.149987  [38464/60000]\n",
      "loss: 0.029576  [44864/60000]\n",
      "loss: 0.101925  [51264/60000]\n",
      "loss: 0.077203  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 95.9%, Avg loss: 0.134366 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.175437  [   64/60000]\n",
      "loss: 0.075377  [ 6464/60000]\n",
      "loss: 0.165189  [12864/60000]\n",
      "loss: 0.107919  [19264/60000]\n",
      "loss: 0.061090  [25664/60000]\n",
      "loss: 0.206451  [32064/60000]\n",
      "loss: 0.077826  [38464/60000]\n",
      "loss: 0.269873  [44864/60000]\n",
      "loss: 0.020039  [51264/60000]\n",
      "loss: 0.144841  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, Avg loss: 0.124318 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.089466  [   64/60000]\n",
      "loss: 0.093003  [ 6464/60000]\n",
      "loss: 0.153637  [12864/60000]\n",
      "loss: 0.099511  [19264/60000]\n",
      "loss: 0.137800  [25664/60000]\n",
      "loss: 0.024861  [32064/60000]\n",
      "loss: 0.164126  [38464/60000]\n",
      "loss: 0.053568  [44864/60000]\n",
      "loss: 0.168318  [51264/60000]\n",
      "loss: 0.093670  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.095750 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.086696  [   64/60000]\n",
      "loss: 0.064215  [ 6464/60000]\n",
      "loss: 0.125195  [12864/60000]\n",
      "loss: 0.204648  [19264/60000]\n",
      "loss: 0.035175  [25664/60000]\n",
      "loss: 0.058902  [32064/60000]\n",
      "loss: 0.024874  [38464/60000]\n",
      "loss: 0.139980  [44864/60000]\n",
      "loss: 0.136691  [51264/60000]\n",
      "loss: 0.022562  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.3%, Avg loss: 0.088952 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.058208  [   64/60000]\n",
      "loss: 0.079018  [ 6464/60000]\n",
      "loss: 0.155989  [12864/60000]\n",
      "loss: 0.236145  [19264/60000]\n",
      "loss: 0.057211  [25664/60000]\n",
      "loss: 0.105182  [32064/60000]\n",
      "loss: 0.026428  [38464/60000]\n",
      "loss: 0.057686  [44864/60000]\n",
      "loss: 0.068802  [51264/60000]\n",
      "loss: 0.063398  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.084807 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.018240  [   64/60000]\n",
      "loss: 0.025969  [ 6464/60000]\n",
      "loss: 0.145554  [12864/60000]\n",
      "loss: 0.029331  [19264/60000]\n",
      "loss: 0.184337  [25664/60000]\n",
      "loss: 0.068942  [32064/60000]\n",
      "loss: 0.021547  [38464/60000]\n",
      "loss: 0.058110  [44864/60000]\n",
      "loss: 0.019401  [51264/60000]\n",
      "loss: 0.032706  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.074564 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.066322  [   64/60000]\n",
      "loss: 0.016527  [ 6464/60000]\n",
      "loss: 0.046885  [12864/60000]\n",
      "loss: 0.020639  [19264/60000]\n",
      "loss: 0.058421  [25664/60000]\n",
      "loss: 0.065612  [32064/60000]\n",
      "loss: 0.061348  [38464/60000]\n",
      "loss: 0.072662  [44864/60000]\n",
      "loss: 0.082618  [51264/60000]\n",
      "loss: 0.038340  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.081944 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.028945  [   64/60000]\n",
      "loss: 0.016406  [ 6464/60000]\n",
      "loss: 0.051839  [12864/60000]\n",
      "loss: 0.022421  [19264/60000]\n",
      "loss: 0.038999  [25664/60000]\n",
      "loss: 0.091933  [32064/60000]\n",
      "loss: 0.026757  [38464/60000]\n",
      "loss: 0.036919  [44864/60000]\n",
      "loss: 0.023041  [51264/60000]\n",
      "loss: 0.072590  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.082256 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.082466  [   64/60000]\n",
      "loss: 0.037348  [ 6464/60000]\n",
      "loss: 0.018799  [12864/60000]\n",
      "loss: 0.038122  [19264/60000]\n",
      "loss: 0.063509  [25664/60000]\n",
      "loss: 0.030300  [32064/60000]\n",
      "loss: 0.010115  [38464/60000]\n",
      "loss: 0.040777  [44864/60000]\n",
      "loss: 0.047416  [51264/60000]\n",
      "loss: 0.087614  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.9%, Avg loss: 0.069770 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.010486  [   64/60000]\n",
      "loss: 0.031946  [ 6464/60000]\n",
      "loss: 0.101638  [12864/60000]\n",
      "loss: 0.019161  [19264/60000]\n",
      "loss: 0.045501  [25664/60000]\n",
      "loss: 0.019355  [32064/60000]\n",
      "loss: 0.004152  [38464/60000]\n",
      "loss: 0.074424  [44864/60000]\n",
      "loss: 0.011413  [51264/60000]\n",
      "loss: 0.014528  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.066795 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.078099  [   64/60000]\n",
      "loss: 0.036998  [ 6464/60000]\n",
      "loss: 0.061605  [12864/60000]\n",
      "loss: 0.040200  [19264/60000]\n",
      "loss: 0.037104  [25664/60000]\n",
      "loss: 0.044862  [32064/60000]\n",
      "loss: 0.030143  [38464/60000]\n",
      "loss: 0.020953  [44864/60000]\n",
      "loss: 0.019043  [51264/60000]\n",
      "loss: 0.090692  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.066215 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.014445  [   64/60000]\n",
      "loss: 0.020392  [ 6464/60000]\n",
      "loss: 0.019420  [12864/60000]\n",
      "loss: 0.008912  [19264/60000]\n",
      "loss: 0.020029  [25664/60000]\n",
      "loss: 0.023490  [32064/60000]\n",
      "loss: 0.007116  [38464/60000]\n",
      "loss: 0.009756  [44864/60000]\n",
      "loss: 0.049657  [51264/60000]\n",
      "loss: 0.030855  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.064591 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.052074  [   64/60000]\n",
      "loss: 0.016438  [ 6464/60000]\n",
      "loss: 0.009064  [12864/60000]\n",
      "loss: 0.011181  [19264/60000]\n",
      "loss: 0.099403  [25664/60000]\n",
      "loss: 0.032057  [32064/60000]\n",
      "loss: 0.025071  [38464/60000]\n",
      "loss: 0.034177  [44864/60000]\n",
      "loss: 0.021937  [51264/60000]\n",
      "loss: 0.043360  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.9%, Avg loss: 0.064177 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.065823  [   64/60000]\n",
      "loss: 0.009610  [ 6464/60000]\n",
      "loss: 0.006735  [12864/60000]\n",
      "loss: 0.015225  [19264/60000]\n",
      "loss: 0.016056  [25664/60000]\n",
      "loss: 0.006144  [32064/60000]\n",
      "loss: 0.009461  [38464/60000]\n",
      "loss: 0.016456  [44864/60000]\n",
      "loss: 0.030529  [51264/60000]\n",
      "loss: 0.001600  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.063795 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.009474  [   64/60000]\n",
      "loss: 0.007372  [ 6464/60000]\n",
      "loss: 0.002241  [12864/60000]\n",
      "loss: 0.010625  [19264/60000]\n",
      "loss: 0.004217  [25664/60000]\n",
      "loss: 0.012843  [32064/60000]\n",
      "loss: 0.015632  [38464/60000]\n",
      "loss: 0.009688  [44864/60000]\n",
      "loss: 0.002692  [51264/60000]\n",
      "loss: 0.005715  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.068842 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.011375  [   64/60000]\n",
      "loss: 0.064755  [ 6464/60000]\n",
      "loss: 0.002873  [12864/60000]\n",
      "loss: 0.006861  [19264/60000]\n",
      "loss: 0.003411  [25664/60000]\n",
      "loss: 0.005776  [32064/60000]\n",
      "loss: 0.019444  [38464/60000]\n",
      "loss: 0.004261  [44864/60000]\n",
      "loss: 0.012846  [51264/60000]\n",
      "loss: 0.020422  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.9%, Avg loss: 0.066235 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.031018  [   64/60000]\n",
      "loss: 0.011786  [ 6464/60000]\n",
      "loss: 0.011294  [12864/60000]\n",
      "loss: 0.012732  [19264/60000]\n",
      "loss: 0.009296  [25664/60000]\n",
      "loss: 0.007521  [32064/60000]\n",
      "loss: 0.003750  [38464/60000]\n",
      "loss: 0.019401  [44864/60000]\n",
      "loss: 0.007697  [51264/60000]\n",
      "loss: 0.005069  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.060411 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.006952  [   64/60000]\n",
      "loss: 0.006036  [ 6464/60000]\n",
      "loss: 0.026056  [12864/60000]\n",
      "loss: 0.010518  [19264/60000]\n",
      "loss: 0.002604  [25664/60000]\n",
      "loss: 0.001771  [32064/60000]\n",
      "loss: 0.004564  [38464/60000]\n",
      "loss: 0.006075  [44864/60000]\n",
      "loss: 0.005518  [51264/60000]\n",
      "loss: 0.012699  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.068183 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.016957  [   64/60000]\n",
      "loss: 0.123838  [ 6464/60000]\n",
      "loss: 0.045888  [12864/60000]\n",
      "loss: 0.007741  [19264/60000]\n",
      "loss: 0.019638  [25664/60000]\n",
      "loss: 0.021766  [32064/60000]\n",
      "loss: 0.003270  [38464/60000]\n",
      "loss: 0.013504  [44864/60000]\n",
      "loss: 0.008405  [51264/60000]\n",
      "loss: 0.005709  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.9%, Avg loss: 0.067568 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.003501  [   64/60000]\n",
      "loss: 0.011229  [ 6464/60000]\n",
      "loss: 0.002042  [12864/60000]\n",
      "loss: 0.012450  [19264/60000]\n",
      "loss: 0.006128  [25664/60000]\n",
      "loss: 0.001601  [32064/60000]\n",
      "loss: 0.001558  [38464/60000]\n",
      "loss: 0.003344  [44864/60000]\n",
      "loss: 0.016347  [51264/60000]\n",
      "loss: 0.010550  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.061517 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.012364  [   64/60000]\n",
      "loss: 0.005832  [ 6464/60000]\n",
      "loss: 0.000969  [12864/60000]\n",
      "loss: 0.010795  [19264/60000]\n",
      "loss: 0.004952  [25664/60000]\n",
      "loss: 0.036033  [32064/60000]\n",
      "loss: 0.005867  [38464/60000]\n",
      "loss: 0.014159  [44864/60000]\n",
      "loss: 0.007677  [51264/60000]\n",
      "loss: 0.001302  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.065660 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.017188  [   64/60000]\n",
      "loss: 0.005944  [ 6464/60000]\n",
      "loss: 0.001210  [12864/60000]\n",
      "loss: 0.002341  [19264/60000]\n",
      "loss: 0.006031  [25664/60000]\n",
      "loss: 0.003891  [32064/60000]\n",
      "loss: 0.006367  [38464/60000]\n",
      "loss: 0.011910  [44864/60000]\n",
      "loss: 0.007445  [51264/60000]\n",
      "loss: 0.049283  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.062713 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.005880  [   64/60000]\n",
      "loss: 0.011140  [ 6464/60000]\n",
      "loss: 0.003350  [12864/60000]\n",
      "loss: 0.012416  [19264/60000]\n",
      "loss: 0.001382  [25664/60000]\n",
      "loss: 0.003003  [32064/60000]\n",
      "loss: 0.002052  [38464/60000]\n",
      "loss: 0.018491  [44864/60000]\n",
      "loss: 0.002756  [51264/60000]\n",
      "loss: 0.004755  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.060494 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.004183  [   64/60000]\n",
      "loss: 0.003313  [ 6464/60000]\n",
      "loss: 0.006398  [12864/60000]\n",
      "loss: 0.002931  [19264/60000]\n",
      "loss: 0.002075  [25664/60000]\n",
      "loss: 0.008491  [32064/60000]\n",
      "loss: 0.000897  [38464/60000]\n",
      "loss: 0.007235  [44864/60000]\n",
      "loss: 0.004588  [51264/60000]\n",
      "loss: 0.001519  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.064816 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.002035  [   64/60000]\n",
      "loss: 0.005820  [ 6464/60000]\n",
      "loss: 0.019017  [12864/60000]\n",
      "loss: 0.005414  [19264/60000]\n",
      "loss: 0.005054  [25664/60000]\n",
      "loss: 0.005587  [32064/60000]\n",
      "loss: 0.001100  [38464/60000]\n",
      "loss: 0.001805  [44864/60000]\n",
      "loss: 0.003572  [51264/60000]\n",
      "loss: 0.041575  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.062764 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.005929  [   64/60000]\n",
      "loss: 0.002233  [ 6464/60000]\n",
      "loss: 0.004148  [12864/60000]\n",
      "loss: 0.002900  [19264/60000]\n",
      "loss: 0.004814  [25664/60000]\n",
      "loss: 0.004056  [32064/60000]\n",
      "loss: 0.003289  [38464/60000]\n",
      "loss: 0.003330  [44864/60000]\n",
      "loss: 0.002159  [51264/60000]\n",
      "loss: 0.006536  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.062510 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.000552  [   64/60000]\n",
      "loss: 0.002328  [ 6464/60000]\n",
      "loss: 0.001339  [12864/60000]\n",
      "loss: 0.006972  [19264/60000]\n",
      "loss: 0.001997  [25664/60000]\n",
      "loss: 0.001812  [32064/60000]\n",
      "loss: 0.008949  [38464/60000]\n",
      "loss: 0.003447  [44864/60000]\n",
      "loss: 0.003238  [51264/60000]\n",
      "loss: 0.007155  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.063202 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.000919  [   64/60000]\n",
      "loss: 0.001799  [ 6464/60000]\n",
      "loss: 0.010038  [12864/60000]\n",
      "loss: 0.000932  [19264/60000]\n",
      "loss: 0.001146  [25664/60000]\n",
      "loss: 0.002752  [32064/60000]\n",
      "loss: 0.003647  [38464/60000]\n",
      "loss: 0.001984  [44864/60000]\n",
      "loss: 0.002417  [51264/60000]\n",
      "loss: 0.005001  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.063618 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.000900  [   64/60000]\n",
      "loss: 0.003996  [ 6464/60000]\n",
      "loss: 0.002760  [12864/60000]\n",
      "loss: 0.001364  [19264/60000]\n",
      "loss: 0.001735  [25664/60000]\n",
      "loss: 0.006219  [32064/60000]\n",
      "loss: 0.018842  [38464/60000]\n",
      "loss: 0.001550  [44864/60000]\n",
      "loss: 0.004020  [51264/60000]\n",
      "loss: 0.004305  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.062987 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.002885  [   64/60000]\n",
      "loss: 0.000747  [ 6464/60000]\n",
      "loss: 0.002255  [12864/60000]\n",
      "loss: 0.001018  [19264/60000]\n",
      "loss: 0.002249  [25664/60000]\n",
      "loss: 0.000931  [32064/60000]\n",
      "loss: 0.007566  [38464/60000]\n",
      "loss: 0.003826  [44864/60000]\n",
      "loss: 0.001698  [51264/60000]\n",
      "loss: 0.006245  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.062062 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.006433  [   64/60000]\n",
      "loss: 0.003103  [ 6464/60000]\n",
      "loss: 0.000771  [12864/60000]\n",
      "loss: 0.001891  [19264/60000]\n",
      "loss: 0.003848  [25664/60000]\n",
      "loss: 0.003005  [32064/60000]\n",
      "loss: 0.002253  [38464/60000]\n",
      "loss: 0.002060  [44864/60000]\n",
      "loss: 0.002106  [51264/60000]\n",
      "loss: 0.005071  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.064450 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.003794  [   64/60000]\n",
      "loss: 0.003096  [ 6464/60000]\n",
      "loss: 0.006982  [12864/60000]\n",
      "loss: 0.005842  [19264/60000]\n",
      "loss: 0.001782  [25664/60000]\n",
      "loss: 0.001385  [32064/60000]\n",
      "loss: 0.003172  [38464/60000]\n",
      "loss: 0.004311  [44864/60000]\n",
      "loss: 0.006924  [51264/60000]\n",
      "loss: 0.002262  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.064844 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./model/model_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x28464aa00>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import  matplotlib.pyplot as plt\n",
    "x = torch.tensor([[0, 0, 0, 0, 0, 0, 0],\n",
    "              [0, 0, 1, 1, 1, 0, 0],\n",
    "              [0, 0, 1, 0, 1, 0, 0],\n",
    "              [0, 0, 1, 1, 1, 0, 0],\n",
    "              [0, 0, 0, 0, 1, 0, 0],\n",
    "              [0, 0, 1, 1, 1, 0, 0],\n",
    "              [0, 0, 0, 0, 0, 0, 0]])\n",
    "\n",
    "# upscale to 28x28\n",
    "x = torch.kron(x, torch.ones((4, 4)))\n",
    "\n",
    "plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "\n",
    "model.load_state_dict(torch.load('./model/model_weights.pth'))\n",
    "\n",
    "x = x.flatten() / 255.0\n",
    "x = x.view(1, 784)\n",
    "pred = model(x)\n",
    "\n",
    "torch.argmax(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction = 8\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "img = Image.open(\"./testdata/three.png\").resize((28, 28)).convert(\"L\")\n",
    "img_tensor = torch.tensor(np.array(img))\n",
    "\n",
    "\n",
    "# upscale to 28x28\n",
    "\n",
    "flat_img = img_tensor.flatten() / 255.0\n",
    "input_img = flat_img.view(-1, 784)\n",
    "\n",
    "model = NeuralNetwork()\n",
    "model.load_state_dict(torch.load(\"./model/model_weights.pth\"))\n",
    "\n",
    "pred = model(input_img)\n",
    "print(f\"Prediction = {pred.argmax().item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
